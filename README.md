# movieSpider
这个项目用scrapy分析了一组网站，通过phantomjs处理必须要浏览器渲染的页面，并专门用nodejs做了后端数据处理，和前端页面展示。

首先，这个项目其实不是一个通用爬虫，除了爬虫以外，还有一组数据处理工具。

对站点的分析也是针对性的，不排除后面会有拉取不到数据的情况。

因为用了2种语言，分别是python和js，所以有段时间也很纠结，甚至动过自己用nodejs做一个类似scrapy的框架出来，但后来还是忍住了。这个项目应该不太可能有很大的变动了。

nodejs的爬虫尝试其实也都做了，关于html解析和选择器，其实都有比较成熟的方案，而且用法几乎和scrapy一样（scrapy底层做的事其实也不是很多）。

scrapy
---
这是一个流传很广的python爬虫框架。

其实我个人对python并不是很熟悉，所以前面也很折腾，也没有对scrapy框架有很深入的研究，尽可能的通过外部的解决方案解决问题。

选择器这块，主要还是用的xpath和css。

因为scrapy输出主要是item，而且支持json、csv和xml，但对于我来说，我希望后续会有进一步的分析，所以我还是用了数据库，当然，为了省事，直接用的SQLite3，后面的数据处理（movieproc）也是直接读取这个数据库的。

phantomjs
---
这是一套服务器网页渲染器，可以用来处理很多ajax页面。

我们专门利用他自己提供的webservice服务，做了一个渲染服务端，通过http请求渲染页面并返回出来。

目前这块处理得还比较简单，没有考虑很复杂的操作，只是长时间没有新的请求响应就算完结，直接返回客户端。

后面应该会有进一步调整的。